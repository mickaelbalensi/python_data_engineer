{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/studen/mickael/python_data_engineer/hadoop/spark  abs_path: OULAD dataset/studentAssessment.csv\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: hdfs://localhost:9000/user/studen/OULAD dataset/studentAssessment.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Load the datasets\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m student_assessment_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_assessment_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m student_registration_df \u001b[38;5;241m=\u001b[39m load_csv(student_registration_path)\n\u001b[1;32m     31\u001b[0m student_info_df \u001b[38;5;241m=\u001b[39m load_csv(student_info_path)\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mload_csv\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent working directory:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m abs_path:\u001b[39m\u001b[38;5;124m\"\u001b[39m, abs_path)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(abs_path):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mabs_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minferSchema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(path) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m    739\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spark\u001b[39m.\u001b[39m_sc\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mcsv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_spark\u001b[39m.\u001b[39;49m_sc\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mPythonUtils\u001b[39m.\u001b[39;49mtoSeq(path)))\n\u001b[1;32m    741\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    743\u001b[0m     \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: hdfs://localhost:9000/user/studen/OULAD dataset/studentAssessment.csv."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"OULADAnalysis\").getOrCreate()\n",
    "\n",
    "# Paths to the OULAD data CSV files\n",
    "student_assessment_path = \"studentAssessment.csv\"\n",
    "student_registration_path = \"studentRegistration.csv\"\n",
    "student_info_path = \"studentInfo.csv\"\n",
    "vle_path = \"vle.csv\"\n",
    "courses_path = \"courses.csv\"\n",
    "assessments_path = \"assessments.csv\"\n",
    "\n",
    "# Function to check file existence and get absolute path\n",
    "def load_csv(file_path):\n",
    "    # abs_path = os.path.abspath(file_path)\n",
    "    abs_path = f\"OULAD dataset/{file_path}\"\n",
    "    # print the current working directory\n",
    "    print(\"Current working directory:\", os.getcwd(), \" abs_path:\", abs_path)\n",
    "\n",
    "    if os.path.exists(abs_path):\n",
    "        return spark.read.csv(f\"{abs_path}\", header=True, inferSchema=True)\n",
    "    else:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        return None\n",
    "\n",
    "# Load the datasets\n",
    "student_assessment_df = load_csv(student_assessment_path)\n",
    "student_registration_df = load_csv(student_registration_path)\n",
    "student_info_df = load_csv(student_info_path)\n",
    "vle_df = load_csv(vle_path)\n",
    "courses_df = load_csv(courses_path)\n",
    "# assessments_df = load_csv(assessments_path)\n",
    "\n",
    "# Show schema of one of the dataframes to inspect structure\n",
    "student_assessment_df.printSchema()\n",
    "student_registration_df.printSchema()\n",
    "student_info_df.printSchema()\n",
    "vle_df.printSchema()\n",
    "courses_df.printSchema()\n",
    "# assessments_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Translating SQL Queries to PySpark\n",
    "\n",
    "Assume the following SQL queries are from your \"SQL - Analytics\" worksheet, and we'll translate each one into PySpark:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Query: Calculate the Average Score for Each Student**\n",
    "\n",
    "Explanation: We want to calculate the average score for each student in the student_assessment table.\n",
    "\n",
    "`SELECT id_student, AVG(score) AS average_score`\n",
    "\n",
    "`FROM studentAssessment`\n",
    "\n",
    "`GROUP BY id_student;`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 first lines of student_assessment_df:\n",
      "+-------------+----------+--------------+---------+-----+\n",
      "|id_assessment|id_student|date_submitted|is_banked|score|\n",
      "+-------------+----------+--------------+---------+-----+\n",
      "|         1752|     11391|            18|        0|   78|\n",
      "|         1752|     28400|            22|        0|   70|\n",
      "|         1752|     31604|            17|        0|   72|\n",
      "|         1752|     32885|            26|        0|   69|\n",
      "|         1752|     38053|            19|        0|   79|\n",
      "+-------------+----------+--------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " 5 lines of student 11391:\n",
      "+-------------+----------+--------------+---------+-----+\n",
      "|id_assessment|id_student|date_submitted|is_banked|score|\n",
      "+-------------+----------+--------------+---------+-----+\n",
      "|         1752|     11391|            18|        0|   78|\n",
      "|         1753|     11391|            53|        0|   85|\n",
      "|         1754|     11391|           115|        0|   80|\n",
      "|         1755|     11391|           164|        0|   85|\n",
      "|         1756|     11391|           212|        0|   82|\n",
      "+-------------+----------+--------------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_assessment_df.createOrReplaceTempView(\"student_assessment\")\n",
    "print('5 first lines of student_assessment_df:')\n",
    "student_assessment_df.show(5)\n",
    "\n",
    "print('\\n 5 lines of student 11391:')\n",
    "student_assessment_df.filter(student_assessment_df[\"id_student\"] == 11391).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|id_student|    average_score|\n",
      "+----------+-----------------+\n",
      "|    180753|             53.4|\n",
      "|    324084|             57.6|\n",
      "|   2057803|             66.0|\n",
      "|    486656|87.72727272727273|\n",
      "|    502604|72.36363636363636|\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a temporary SQL view\n",
    "\n",
    "# Write the SQL query\n",
    "sql_query = \"\"\"\n",
    "    SELECT id_student, AVG(score) AS average_score\n",
    "    FROM student_assessment\n",
    "    GROUP BY id_student\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "avg_score_sql_df = spark.sql(sql_query)\n",
    "\n",
    "# Show the result\n",
    "avg_score_sql_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|id_student|    average_score|\n",
      "+----------+-----------------+\n",
      "|    180753|             53.4|\n",
      "|    324084|             57.6|\n",
      "|   2057803|             66.0|\n",
      "|    486656|87.72727272727273|\n",
      "|    502604|72.36363636363636|\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Group by id_student and calculate the average score\n",
    "avg_score_df = student_assessment_df.groupBy(\"id_student\").agg(F.avg(\"score\").alias(\"average_score\"))\n",
    "avg_score_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_df = student_assessment_df.groupBy(\"id_student\").agg(F.avg(\"score\").alias(\"average_score\"))\n",
    "avg_score_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Query: Find the Number of Students for Each Course**\n",
    "\n",
    "Explanation: This query will return the number of students enrolled in each course. \n",
    "\n",
    "Weâ€™ll need to join the student_registration table with the courses table to get the course information.\n",
    "\n",
    "**`SELECT code_module, code_presentation, COUNT(id_student) AS num_students`**\n",
    "\n",
    "**`FROM studentRegistration`**\n",
    "\n",
    "**`GROUP BY code_module, code_presentation;`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+-----------------+-------------------+\n",
      "|code_module|code_presentation|id_student|date_registration|date_unregistration|\n",
      "+-----------+-----------------+----------+-----------------+-------------------+\n",
      "|        AAA|            2013J|     11391|             -159|               NULL|\n",
      "|        AAA|            2013J|     28400|              -53|               NULL|\n",
      "|        AAA|            2013J|     30268|              -92|                 12|\n",
      "|        AAA|            2013J|     31604|              -52|               NULL|\n",
      "|        AAA|            2013J|     32885|             -176|               NULL|\n",
      "+-----------+-----------------+----------+-----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_registration_df.createOrReplaceTempView(\"student_registration\")\n",
    "student_registration_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-----------------+\n",
      "|code_module|code_presentation|count(id_student)|\n",
      "+-----------+-----------------+-----------------+\n",
      "|        FFF|            2013J|             2283|\n",
      "|        BBB|            2013J|             2237|\n",
      "|        BBB|            2014J|             2292|\n",
      "|        EEE|            2014J|             1188|\n",
      "|        BBB|            2014B|             1613|\n",
      "+-----------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\"\n",
    "select code_module, code_presentation, count(id_student)\n",
    "from student_registration\n",
    "group by code_module, code_presentation\"\"\"\n",
    "\n",
    "num_students_sql_df = spark.sql(sql_query)\n",
    "num_students_sql_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+------------+\n",
      "|code_module|code_presentation|num_students|\n",
      "+-----------+-----------------+------------+\n",
      "|        FFF|            2013J|        2283|\n",
      "|        BBB|            2013J|        2237|\n",
      "|        BBB|            2014J|        2292|\n",
      "|        EEE|            2014J|        1188|\n",
      "|        BBB|            2014B|        1613|\n",
      "+-----------+-----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_registration_df.groupBy(\"code_module\", \"code_presentation\") \\\n",
    "    .agg(F.count(\"id_student\").alias(\"num_students\")) \\\n",
    "    .show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Query: Get Students with Scores Above Average**\n",
    "\n",
    "**Explanation:** We want to find students whose score is above the average score for their respective courses. \n",
    "\n",
    "This will require calculating the average score for each course and then filtering the students accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------+---------+-----+\n",
      "|id_assessment|id_student|date_submitted|is_banked|score|\n",
      "+-------------+----------+--------------+---------+-----+\n",
      "|         1752|     11391|            18|        0|   78|\n",
      "|         1752|     28400|            22|        0|   70|\n",
      "|         1752|     31604|            17|        0|   72|\n",
      "|         1752|     32885|            26|        0|   69|\n",
      "|         1752|     38053|            19|        0|   79|\n",
      "+-------------+----------+--------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+-----------------+----------+-----------------+-------------------+\n",
      "|code_module|code_presentation|id_student|date_registration|date_unregistration|\n",
      "+-----------+-----------------+----------+-----------------+-------------------+\n",
      "|        AAA|            2013J|     11391|             -159|               NULL|\n",
      "|        AAA|            2013J|     28400|              -53|               NULL|\n",
      "|        AAA|            2013J|     30268|              -92|                 12|\n",
      "|        AAA|            2013J|     31604|              -52|               NULL|\n",
      "|        AAA|            2013J|     32885|             -176|               NULL|\n",
      "+-----------+-----------------+----------+-----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_assessment_df.createOrReplaceTempView(\"student_assessment\")\n",
    "student_registration_df.createOrReplaceTempView(\"student_registration\")\n",
    "student_assessment_df.show(5)\n",
    "student_registration_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----+----------------+\n",
      "|id_student|id_assessment|score|       avg_score|\n",
      "+----------+-------------+-----+----------------+\n",
      "|     11391|         1752|   78|70.3072625698324|\n",
      "|     31604|         1752|   72|70.3072625698324|\n",
      "|     38053|         1752|   79|70.3072625698324|\n",
      "|     45642|         1752|   72|70.3072625698324|\n",
      "|     52130|         1752|   72|70.3072625698324|\n",
      "+----------+-------------+-----+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_assessment_df.createOrReplaceTempView(\"student_assessment\")\n",
    "student_registration_df.createOrReplaceTempView(\"student_registration\")\n",
    "\n",
    "sql_query = \"\"\"\n",
    "    with avg_scores as (\n",
    "        select id_assessment, avg(score) as avg_score\n",
    "        from student_assessment\n",
    "        group by id_assessment\n",
    "    ) \n",
    "\n",
    "    select sa.id_student, sa.id_assessment, sa.score, as.avg_score\n",
    "    from student_assessment sa\n",
    "    join avg_scores as\n",
    "    on sa.id_assessment = as.id_assessment \n",
    "    where sa.score > as.avg_score;\n",
    "\"\"\"\n",
    "\n",
    "above_avg_sql_df = spark.sql(sql_query)\n",
    "above_avg_sql_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Student average by Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+--------------+\n",
      "|code_module|code_presentation|id_student|stud_avg_score|\n",
      "+-----------+-----------------+----------+--------------+\n",
      "|        AAA|            2013J|   1758449|          61.0|\n",
      "|        AAA|            2013J|   2645733|          82.6|\n",
      "|        AAA|            2013J|    383254|          75.6|\n",
      "|        AAA|            2013J|    319047|          78.4|\n",
      "|        AAA|            2013J|    442442|          40.5|\n",
      "|        AAA|            2013J|   2574583|          70.8|\n",
      "|        AAA|            2013J|     32885|          54.4|\n",
      "|        AAA|            2013J|   1976139|         67.25|\n",
      "|        AAA|            2013J|   2678643|          71.4|\n",
      "|        AAA|            2013J|   2641155|          79.2|\n",
      "+-----------+-----------------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "student_assessment_df.createOrReplaceTempView(\"student_assessment\")\n",
    "student_registration_df.createOrReplaceTempView(\"student_registration\")\n",
    "\n",
    "sqlq = '''\n",
    "        SELECT s.code_module, s.code_presentation, s.id_student,  AVG(a.score) AS stud_avg_score\n",
    "        FROM student_assessment a\n",
    "        JOIN student_registration s ON a.id_student = s.id_student\n",
    "        GROUP BY s.code_module, s.code_presentation, s.id_student\n",
    "        order by s.code_module, s.code_presentation;\n",
    "        '''\n",
    "\n",
    "avg_scores_df = spark.sql(sqlq)\n",
    "avg_scores_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Average Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-----------------+\n",
      "|code_module|code_presentation| course_avg_score|\n",
      "+-----------+-----------------+-----------------+\n",
      "|        AAA|            2013J|68.70252976190477|\n",
      "|        AAA|            2014J|67.75304570807913|\n",
      "|        BBB|            2013B|77.01329487886625|\n",
      "|        BBB|            2013J|76.85449436782734|\n",
      "|        BBB|            2014B| 76.9498548327345|\n",
      "|        BBB|            2014J|64.85704275743726|\n",
      "|        CCC|            2014B|68.43857689587726|\n",
      "|        CCC|            2014J|73.47009178050807|\n",
      "|        DDD|            2013B|65.79623979608903|\n",
      "|        DDD|            2013J|66.98399242550796|\n",
      "|        DDD|            2014B|66.15579808673954|\n",
      "|        DDD|            2014J|69.74450526171822|\n",
      "|        EEE|            2013J|75.64172984208012|\n",
      "|        EEE|            2014B|72.36605001479646|\n",
      "|        EEE|            2014J|79.53356797860346|\n",
      "|        FFF|            2013B|75.82871827428937|\n",
      "|        FFF|            2013J|74.55298800862386|\n",
      "|        FFF|            2014B|74.24259719865462|\n",
      "|        FFF|            2014J|76.09906395335442|\n",
      "|        GGG|            2013J|77.93457572407263|\n",
      "+-----------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_assessment_df.createOrReplaceTempView(\"student_assessment\")\n",
    "student_registration_df.createOrReplaceTempView(\"student_registration\")\n",
    "\n",
    "sqlq = '''\n",
    "with stud_avg_scores_by_courses as (\n",
    "    SELECT s.code_module, s.code_presentation, s.id_student,  AVG(a.score) AS stud_avg_score\n",
    "        FROM student_assessment a\n",
    "        JOIN student_registration s ON a.id_student = s.id_student\n",
    "        GROUP BY s.code_module, s.code_presentation, s.id_student\n",
    "        order by s.code_module, s.code_presentation\n",
    ")\n",
    "select sabc.code_module, sabc.code_presentation, avg(sabc.stud_avg_score) as course_avg_score\n",
    "from stud_avg_scores_by_courses sabc\n",
    "group by sabc.code_module, sabc.code_presentation;\n",
    "'''\n",
    "\n",
    "avg_scores_df = spark.sql(sqlq)\n",
    "avg_scores_df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Average student > Average course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+-----------------+-----------------+\n",
      "|code_module|code_presentation|id_student|   stud_avg_score| course_avg_score|\n",
      "+-----------+-----------------+----------+-----------------+-----------------+\n",
      "|        AAA|            2013J|     62155|             76.0|68.70252976190477|\n",
      "|        AAA|            2013J|    319047|             78.4|68.70252976190477|\n",
      "|        AAA|            2014J|    375260|             71.4|67.75304570807913|\n",
      "|        BBB|            2013B|   2380539|             82.1|77.01329487886625|\n",
      "|        BBB|            2013B|    298476|81.63636363636364|77.01329487886625|\n",
      "|        BBB|            2013B|    340831|85.83333333333333|77.01329487886625|\n",
      "|        BBB|            2013B|    558689|             80.6|77.01329487886625|\n",
      "|        BBB|            2013J|    546941|81.63636363636364|76.85449436782734|\n",
      "|        BBB|            2013J|    568609|             84.6|76.85449436782734|\n",
      "|        BBB|            2013J|   2115711|             85.6|76.85449436782734|\n",
      "|        BBB|            2014B|    621301|             84.2| 76.9498548327345|\n",
      "|        BBB|            2014B|    622505|86.36363636363636| 76.9498548327345|\n",
      "|        BBB|            2014B|    634286|77.81818181818181| 76.9498548327345|\n",
      "|        BBB|            2014B|    634481|81.36363636363636| 76.9498548327345|\n",
      "|        BBB|            2014J|     47891|65.66666666666667|64.85704275743726|\n",
      "|        BBB|            2014J|    485853|            100.0|64.85704275743726|\n",
      "|        GGG|            2013J|    610405|             86.0|77.93457572407263|\n",
      "|        BBB|            2014J|    630286|            100.0|64.85704275743726|\n",
      "|        BBB|            2014J|    643321|             84.4|64.85704275743726|\n",
      "|        CCC|            2014B|    134025|87.27777777777777|68.43857689587726|\n",
      "+-----------+-----------------+----------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_assessment_df.createOrReplaceTempView(\"student_assessment\")\n",
    "student_registration_df.createOrReplaceTempView(\"student_registration\")\n",
    "\n",
    "sqlq = ''' \n",
    "with stud_avg_scores_by_courses as (\n",
    "    SELECT s.code_module, s.code_presentation, s.id_student,  AVG(a.score) AS stud_avg_score\n",
    "        FROM student_assessment a\n",
    "        JOIN student_registration s ON a.id_student = s.id_student\n",
    "        GROUP BY s.code_module, s.code_presentation, s.id_student\n",
    "        order by s.code_module, s.code_presentation\n",
    "), course_avg_scores as (\n",
    "    select sabc.code_module, sabc.code_presentation, avg(sabc.stud_avg_score) as course_avg_score\n",
    "    from stud_avg_scores_by_courses sabc\n",
    "    group by sabc.code_module, sabc.code_presentation\n",
    ")\n",
    "select cas.code_module, cas.code_presentation, sabc.id_student, sabc.stud_avg_score,  cas.course_avg_score\n",
    "from stud_avg_scores_by_courses sabc\n",
    "join course_avg_scores cas\n",
    "on sabc.code_module = cas.code_module and sabc.code_presentation = cas.code_presentation\n",
    "where sabc.stud_avg_score > cas.course_avg_score;\n",
    "'''\n",
    "\n",
    "avg_scores_df = spark.sql(sqlq)\n",
    "avg_scores_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+-----------------+-----------------+\n",
      "|code_module|code_presentation|id_student|   stud_avg_score| course_avg_score|\n",
      "+-----------+-----------------+----------+-----------------+-----------------+\n",
      "|        AAA|            2013J|     62155|             76.0|68.70252976190477|\n",
      "|        AAA|            2013J|    319047|             78.4|68.70252976190477|\n",
      "|        AAA|            2014J|    375260|             71.4|67.75304570807913|\n",
      "|        BBB|            2013B|   2380539|             82.1|77.01329487886625|\n",
      "|        BBB|            2013B|    298476|81.63636363636364|77.01329487886625|\n",
      "|        BBB|            2013B|    340831|85.83333333333333|77.01329487886625|\n",
      "|        BBB|            2013B|    558689|             80.6|77.01329487886625|\n",
      "|        BBB|            2013J|    546941|81.63636363636364|76.85449436782734|\n",
      "|        BBB|            2013J|    568609|             84.6|76.85449436782734|\n",
      "|        BBB|            2013J|   2115711|             85.6|76.85449436782734|\n",
      "|        BBB|            2014B|    621301|             84.2| 76.9498548327345|\n",
      "|        BBB|            2014B|    622505|86.36363636363636| 76.9498548327345|\n",
      "|        BBB|            2014B|    634286|77.81818181818181| 76.9498548327345|\n",
      "|        BBB|            2014B|    634481|81.36363636363636| 76.9498548327345|\n",
      "|        BBB|            2014J|     47891|65.66666666666667|64.85704275743726|\n",
      "|        BBB|            2014J|    485853|            100.0|64.85704275743726|\n",
      "|        GGG|            2013J|    610405|             86.0|77.93457572407263|\n",
      "|        BBB|            2014J|    630286|            100.0|64.85704275743726|\n",
      "|        BBB|            2014J|    643321|             84.4|64.85704275743726|\n",
      "|        CCC|            2014B|    134025|87.27777777777777|68.43857689587726|\n",
      "+-----------+-----------------+----------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "'Filter ('stud_avg_score > 'course_avg_score)\n",
      "+- Project [code_module#44, code_presentation#45, id_student#18, stud_avg_score#1316, course_avg_score#1326]\n",
      "   +- Join Inner, ((code_module#44 = code_module#1335) AND (code_presentation#45 = code_presentation#1336))\n",
      "      :- Aggregate [code_module#44, code_presentation#45, id_student#18], [code_module#44, code_presentation#45, id_student#18, avg(score#21) AS stud_avg_score#1316]\n",
      "      :  +- Project [id_student#18, id_assessment#17, date_submitted#19, is_banked#20, score#21, code_module#44, code_presentation#45, date_registration#47, date_unregistration#48]\n",
      "      :     +- Join Inner, (id_student#18 = id_student#46)\n",
      "      :        :- Relation [id_assessment#17,id_student#18,date_submitted#19,is_banked#20,score#21] csv\n",
      "      :        +- Relation [code_module#44,code_presentation#45,id_student#46,date_registration#47,date_unregistration#48] csv\n",
      "      +- Aggregate [code_module#1335, code_presentation#1336], [code_module#1335, code_presentation#1336, avg(stud_avg_score#1316) AS course_avg_score#1326]\n",
      "         +- Aggregate [code_module#1335, code_presentation#1336, id_student#1331], [code_module#1335, code_presentation#1336, id_student#1331, avg(score#1334) AS stud_avg_score#1316]\n",
      "            +- Project [id_student#1331, id_assessment#1330, date_submitted#1332, is_banked#1333, score#1334, code_module#1335, code_presentation#1336, date_registration#1338, date_unregistration#1339]\n",
      "               +- Join Inner, (id_student#1331 = id_student#1337)\n",
      "                  :- Relation [id_assessment#1330,id_student#1331,date_submitted#1332,is_banked#1333,score#1334] csv\n",
      "                  +- Relation [code_module#1335,code_presentation#1336,id_student#1337,date_registration#1338,date_unregistration#1339] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "code_module: string, code_presentation: string, id_student: int, stud_avg_score: double, course_avg_score: double\n",
      "Filter (stud_avg_score#1316 > course_avg_score#1326)\n",
      "+- Project [code_module#44, code_presentation#45, id_student#18, stud_avg_score#1316, course_avg_score#1326]\n",
      "   +- Join Inner, ((code_module#44 = code_module#1335) AND (code_presentation#45 = code_presentation#1336))\n",
      "      :- Aggregate [code_module#44, code_presentation#45, id_student#18], [code_module#44, code_presentation#45, id_student#18, avg(score#21) AS stud_avg_score#1316]\n",
      "      :  +- Project [id_student#18, id_assessment#17, date_submitted#19, is_banked#20, score#21, code_module#44, code_presentation#45, date_registration#47, date_unregistration#48]\n",
      "      :     +- Join Inner, (id_student#18 = id_student#46)\n",
      "      :        :- Relation [id_assessment#17,id_student#18,date_submitted#19,is_banked#20,score#21] csv\n",
      "      :        +- Relation [code_module#44,code_presentation#45,id_student#46,date_registration#47,date_unregistration#48] csv\n",
      "      +- Aggregate [code_module#1335, code_presentation#1336], [code_module#1335, code_presentation#1336, avg(stud_avg_score#1316) AS course_avg_score#1326]\n",
      "         +- Aggregate [code_module#1335, code_presentation#1336, id_student#1331], [code_module#1335, code_presentation#1336, id_student#1331, avg(score#1334) AS stud_avg_score#1316]\n",
      "            +- Project [id_student#1331, id_assessment#1330, date_submitted#1332, is_banked#1333, score#1334, code_module#1335, code_presentation#1336, date_registration#1338, date_unregistration#1339]\n",
      "               +- Join Inner, (id_student#1331 = id_student#1337)\n",
      "                  :- Relation [id_assessment#1330,id_student#1331,date_submitted#1332,is_banked#1333,score#1334] csv\n",
      "                  +- Relation [code_module#1335,code_presentation#1336,id_student#1337,date_registration#1338,date_unregistration#1339] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [code_module#44, code_presentation#45, id_student#18, stud_avg_score#1316, course_avg_score#1326]\n",
      "+- Join Inner, (((stud_avg_score#1316 > course_avg_score#1326) AND (code_module#44 = code_module#1335)) AND (code_presentation#45 = code_presentation#1336))\n",
      "   :- Filter isnotnull(stud_avg_score#1316)\n",
      "   :  +- Aggregate [code_module#44, code_presentation#45, id_student#18], [code_module#44, code_presentation#45, id_student#18, avg(score#21) AS stud_avg_score#1316]\n",
      "   :     +- Project [id_student#18, score#21, code_module#44, code_presentation#45]\n",
      "   :        +- Join Inner, (id_student#18 = id_student#46)\n",
      "   :           :- Project [id_student#18, score#21]\n",
      "   :           :  +- Filter isnotnull(id_student#18)\n",
      "   :           :     +- Relation [id_assessment#17,id_student#18,date_submitted#19,is_banked#20,score#21] csv\n",
      "   :           +- Project [code_module#44, code_presentation#45, id_student#46]\n",
      "   :              +- Filter (isnotnull(id_student#46) AND (isnotnull(code_module#44) AND isnotnull(code_presentation#45)))\n",
      "   :                 +- Relation [code_module#44,code_presentation#45,id_student#46,date_registration#47,date_unregistration#48] csv\n",
      "   +- Filter isnotnull(course_avg_score#1326)\n",
      "      +- Aggregate [code_module#1335, code_presentation#1336], [code_module#1335, code_presentation#1336, avg(stud_avg_score#1316) AS course_avg_score#1326]\n",
      "         +- Aggregate [code_module#1335, code_presentation#1336, id_student#1331], [code_module#1335, code_presentation#1336, avg(score#1334) AS stud_avg_score#1316]\n",
      "            +- Project [id_student#1331, score#1334, code_module#1335, code_presentation#1336]\n",
      "               +- Join Inner, (id_student#1331 = id_student#1337)\n",
      "                  :- Project [id_student#1331, score#1334]\n",
      "                  :  +- Filter isnotnull(id_student#1331)\n",
      "                  :     +- Relation [id_assessment#1330,id_student#1331,date_submitted#1332,is_banked#1333,score#1334] csv\n",
      "                  +- Project [code_module#1335, code_presentation#1336, id_student#1337]\n",
      "                     +- Filter (isnotnull(id_student#1337) AND (isnotnull(code_module#1335) AND isnotnull(code_presentation#1336)))\n",
      "                        +- Relation [code_module#1335,code_presentation#1336,id_student#1337,date_registration#1338,date_unregistration#1339] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [code_module#44, code_presentation#45, id_student#18, stud_avg_score#1316, course_avg_score#1326]\n",
      "   +- SortMergeJoin [code_module#44, code_presentation#45], [code_module#1335, code_presentation#1336], Inner, (stud_avg_score#1316 > course_avg_score#1326)\n",
      "      :- Sort [code_module#44 ASC NULLS FIRST, code_presentation#45 ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(code_module#44, code_presentation#45, 200), ENSURE_REQUIREMENTS, [plan_id=5431]\n",
      "      :     +- Filter isnotnull(stud_avg_score#1316)\n",
      "      :        +- HashAggregate(keys=[code_module#44, code_presentation#45, id_student#18], functions=[avg(score#21)], output=[code_module#44, code_presentation#45, id_student#18, stud_avg_score#1316])\n",
      "      :           +- Exchange hashpartitioning(code_module#44, code_presentation#45, id_student#18, 200), ENSURE_REQUIREMENTS, [plan_id=5414]\n",
      "      :              +- HashAggregate(keys=[code_module#44, code_presentation#45, id_student#18], functions=[partial_avg(score#21)], output=[code_module#44, code_presentation#45, id_student#18, sum#1364, count#1365L])\n",
      "      :                 +- Project [id_student#18, score#21, code_module#44, code_presentation#45]\n",
      "      :                    +- BroadcastHashJoin [id_student#18], [id_student#46], Inner, BuildRight, false\n",
      "      :                       :- Filter isnotnull(id_student#18)\n",
      "      :                       :  +- FileScan csv [id_student#18,score#21] Batched: false, DataFilters: [isnotnull(id_student#18)], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/user/mickael/oulad/studentAssessment.csv], PartitionFilters: [], PushedFilters: [IsNotNull(id_student)], ReadSchema: struct<id_student:int,score:int>\n",
      "      :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[2, int, false] as bigint)),false), [plan_id=5409]\n",
      "      :                          +- Filter ((isnotnull(id_student#46) AND isnotnull(code_module#44)) AND isnotnull(code_presentation#45))\n",
      "      :                             +- FileScan csv [code_module#44,code_presentation#45,id_student#46] Batched: false, DataFilters: [isnotnull(id_student#46), isnotnull(code_module#44), isnotnull(code_presentation#45)], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/user/mickael/oulad/studentRegistration.csv], PartitionFilters: [], PushedFilters: [IsNotNull(id_student), IsNotNull(code_module), IsNotNull(code_presentation)], ReadSchema: struct<code_module:string,code_presentation:string,id_student:int>\n",
      "      +- Sort [code_module#1335 ASC NULLS FIRST, code_presentation#1336 ASC NULLS FIRST], false, 0\n",
      "         +- Filter isnotnull(course_avg_score#1326)\n",
      "            +- HashAggregate(keys=[code_module#1335, code_presentation#1336], functions=[avg(stud_avg_score#1316)], output=[code_module#1335, code_presentation#1336, course_avg_score#1326])\n",
      "               +- Exchange hashpartitioning(code_module#1335, code_presentation#1336, 200), ENSURE_REQUIREMENTS, [plan_id=5426]\n",
      "                  +- HashAggregate(keys=[code_module#1335, code_presentation#1336], functions=[partial_avg(stud_avg_score#1316)], output=[code_module#1335, code_presentation#1336, sum#1368, count#1369L])\n",
      "                     +- HashAggregate(keys=[code_module#1335, code_presentation#1336, id_student#1331], functions=[avg(score#1334)], output=[code_module#1335, code_presentation#1336, stud_avg_score#1316])\n",
      "                        +- Exchange hashpartitioning(code_module#1335, code_presentation#1336, id_student#1331, 200), ENSURE_REQUIREMENTS, [plan_id=5422]\n",
      "                           +- HashAggregate(keys=[code_module#1335, code_presentation#1336, id_student#1331], functions=[partial_avg(score#1334)], output=[code_module#1335, code_presentation#1336, id_student#1331, sum#1372, count#1373L])\n",
      "                              +- Project [id_student#1331, score#1334, code_module#1335, code_presentation#1336]\n",
      "                                 +- BroadcastHashJoin [id_student#1331], [id_student#1337], Inner, BuildRight, false\n",
      "                                    :- Filter isnotnull(id_student#1331)\n",
      "                                    :  +- FileScan csv [id_student#1331,score#1334] Batched: false, DataFilters: [isnotnull(id_student#1331)], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/user/mickael/oulad/studentAssessment.csv], PartitionFilters: [], PushedFilters: [IsNotNull(id_student)], ReadSchema: struct<id_student:int,score:int>\n",
      "                                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[2, int, false] as bigint)),false), [plan_id=5417]\n",
      "                                       +- Filter ((isnotnull(id_student#1337) AND isnotnull(code_module#1335)) AND isnotnull(code_presentation#1336))\n",
      "                                          +- FileScan csv [code_module#1335,code_presentation#1336,id_student#1337] Batched: false, DataFilters: [isnotnull(id_student#1337), isnotnull(code_module#1335), isnotnull(code_presentation#1336)], Format: CSV, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/user/mickael/oulad/studentRegistration.csv], PartitionFilters: [], PushedFilters: [IsNotNull(id_student), IsNotNull(code_module), IsNotNull(code_presentation)], ReadSchema: struct<code_module:string,code_presentation:string,id_student:int>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "stud_avg_scores_by_courses = student_assessment_df\\\n",
    "    .join(student_registration_df,\"id_student\")\\\n",
    "    .groupBy(\"code_module\", \"code_presentation\", \"id_student\")\\\n",
    "    .agg(F.avg(\"score\").alias(\"stud_avg_score\"))\n",
    "\n",
    "course_avg_scores = stud_avg_scores_by_courses.groupBy(\"code_module\", \"code_presentation\")\\\n",
    "    .agg(F.avg(\"stud_avg_score\").alias(\"course_avg_score\"))\n",
    "\n",
    "higher_student = stud_avg_scores_by_courses.join(course_avg_scores, [\"code_module\", \"code_presentation\"])\\\n",
    "    .filter(F.col(\"stud_avg_score\") > F.col(\"course_avg_score\"))\n",
    "\n",
    "higher_student.show()\n",
    "higher_student.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Query: Find the Number of Attempts for Each Student**\n",
    "\n",
    "Explanation: We want to find how many attempts each student has made. This is stored in the num_of_prev_attempts column in the student_info table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|id_student|num_of_prev_attempts|\n",
      "+----------+--------------------+\n",
      "|     65002|                   1|\n",
      "|     94961|                   1|\n",
      "|    121349|                   1|\n",
      "|    129955|                   1|\n",
      "|    135335|                   1|\n",
      "|    135400|                   1|\n",
      "|    141377|                   1|\n",
      "|    147756|                   1|\n",
      "|    148993|                   1|\n",
      "|    155984|                   1|\n",
      "|    159954|                   1|\n",
      "|    188278|                   1|\n",
      "|    235507|                   1|\n",
      "|    260355|                   1|\n",
      "|    268733|                   1|\n",
      "|    277880|                   1|\n",
      "|    303985|                   1|\n",
      "|    331358|                   1|\n",
      "|    335764|                   1|\n",
      "|    342007|                   1|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrames as temporary SQL views\n",
    "student_info_df.createOrReplaceTempView(\"student_info\")\n",
    "\n",
    "# SQL query to calculate average score per code_module and filter students with scores above the average\n",
    "query = \"\"\"\n",
    "    SELECT id_student, num_of_prev_attempts\n",
    "    FROM student_info\n",
    "    WHERE num_of_prev_attempts > 0;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "above_avg_df = spark.sql(query)\n",
    "\n",
    "# Show the results\n",
    "above_avg_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
      "|code_module|code_presentation|id_student|gender|              region|   highest_education|imd_band|age_band|num_of_prev_attempts|studied_credits|disability|final_result|\n",
      "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
      "|        AAA|            2014J|     65002|     F| East Anglian Region|A Level or Equiva...|  70-80%|    0-35|                   1|             60|         N|        Fail|\n",
      "|        AAA|            2014J|     94961|     M|        South Region|  Lower Than A Level|  70-80%|   35-55|                   1|             60|         N|        Pass|\n",
      "|        AAA|            2014J|    121349|     F|   South West Region|A Level or Equiva...|  40-50%|   35-55|                   1|             60|         N|        Pass|\n",
      "|        AAA|            2014J|    129955|     M|West Midlands Region|A Level or Equiva...|  50-60%|    0-35|                   1|             60|         N|   Withdrawn|\n",
      "|        AAA|            2014J|    135335|     F| East Anglian Region|  Lower Than A Level|  20-30%|    0-35|                   1|            120|         N|   Withdrawn|\n",
      "|        AAA|            2014J|    135400|     F|   South East Region|  Lower Than A Level| 90-100%|   35-55|                   1|             60|         Y|        Pass|\n",
      "|        AAA|            2014J|    141377|     M|   South West Region|A Level or Equiva...| 90-100%|    0-35|                   1|            210|         N|        Pass|\n",
      "|        AAA|            2014J|    147756|     M|        North Region|  Lower Than A Level|  60-70%|    0-35|                   1|            120|         N|        Pass|\n",
      "|        AAA|            2014J|    148993|     F|North Western Region|A Level or Equiva...|  30-40%|   35-55|                   1|             60|         Y|        Pass|\n",
      "|        AAA|            2014J|    155984|     F| East Anglian Region|  Lower Than A Level|  70-80%|    0-35|                   1|            120|         N|        Pass|\n",
      "|        AAA|            2014J|    159954|     M|East Midlands Region|A Level or Equiva...|  40-50%|   35-55|                   1|             60|         N|   Withdrawn|\n",
      "|        AAA|            2014J|    188278|     M|    Yorkshire Region|A Level or Equiva...|  70-80%|   35-55|                   1|             60|         N|        Pass|\n",
      "|        AAA|            2014J|    235507|     M|    Yorkshire Region|A Level or Equiva...| 90-100%|    0-35|                   1|            180|         N|        Pass|\n",
      "|        AAA|            2014J|    260355|     F|       London Region|A Level or Equiva...|  80-90%|   35-55|                   1|            120|         N|   Withdrawn|\n",
      "|        AAA|            2014J|    268733|     M| East Anglian Region|A Level or Equiva...|  30-40%|    0-35|                   1|            120|         N|        Fail|\n",
      "|        AAA|            2014J|    277880|     F|   South East Region|A Level or Equiva...|  60-70%|    0-35|                   1|            120|         N|   Withdrawn|\n",
      "|        AAA|            2014J|    303985|     F|            Scotland|    HE Qualification|  70-80%|    0-35|                   1|             60|         N|        Pass|\n",
      "|        AAA|            2014J|    331358|     F|        South Region|    HE Qualification| 90-100%|   35-55|                   1|             60|         N| Distinction|\n",
      "|        AAA|            2014J|    335764|     F|   South East Region|A Level or Equiva...|  20-30%|    0-35|                   1|             60|         N|        Pass|\n",
      "|        AAA|            2014J|    342007|     F|West Midlands Region|    HE Qualification|  70-80%|    0-35|                   1|             60|         N|        Pass|\n",
      "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter students who have made previous attempts\n",
    "attempts_df = student_info_df.filter(student_info_df.num_of_prev_attempts > 0)\n",
    "attempts_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Query: Calculate the Average Score for Students by Course and Presentation\n",
    "\n",
    "Explanation: We want to calculate the average score for students in each course and presentation.\n",
    "\n",
    "SQL Query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT code_module, code_presentation, AVG(score) AS avg_score\n",
    "FROM studentAssessment sa\n",
    "JOIN studentRegistration sr ON sa.id_student = sr.id_student\n",
    "GROUP BY code_module, code_presentation;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-----------------+\n",
      "|code_module|code_presentation|        avg_score|\n",
      "+-----------+-----------------+-----------------+\n",
      "|        FFF|            2013J|76.69445366987712|\n",
      "|        BBB|            2013J|78.68632312537693|\n",
      "|        BBB|            2014J|66.94286420974524|\n",
      "|        EEE|            2014J|79.57708659655404|\n",
      "|        BBB|            2014B|78.60993044822257|\n",
      "|        GGG|            2014B|79.49848392965434|\n",
      "|        DDD|            2013J|69.90850417615793|\n",
      "|        AAA|            2014J|68.75673981191223|\n",
      "|        DDD|            2014J| 71.4885775862069|\n",
      "|        GGG|            2013J|79.93120233652442|\n",
      "|        FFF|            2014J|78.19184161119645|\n",
      "|        AAA|            2013J|69.50537634408602|\n",
      "|        DDD|            2013B|  69.502701760502|\n",
      "|        CCC|            2014J|75.96365316494686|\n",
      "|        BBB|            2013B|78.84378990380523|\n",
      "|        EEE|            2013J|75.08482728465238|\n",
      "|        FFF|            2014B|76.15621524510223|\n",
      "|        DDD|            2014B|69.18938401048493|\n",
      "|        EEE|            2014B|73.98776936517181|\n",
      "|        CCC|            2014B|73.19797030072382|\n",
      "+-----------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to calculate average score per course and presentation\n",
    "query = \"\"\"\n",
    "    SELECT sr.code_module, sr.code_presentation, AVG(sa.score) AS avg_score\n",
    "    FROM studentAssessment sa\n",
    "    JOIN studentRegistration sr ON sa.id_student = sr.id_student\n",
    "    GROUP BY sr.code_module, sr.code_presentation\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "avg_score_by_course_presentation_df = spark.sql(query)\n",
    "\n",
    "# Show the results\n",
    "avg_score_by_course_presentation_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-----------------+\n",
      "|code_module|code_presentation|        avg_score|\n",
      "+-----------+-----------------+-----------------+\n",
      "|        FFF|            2013J|76.69445366987712|\n",
      "|        BBB|            2013J|78.68632312537693|\n",
      "|        BBB|            2014J|66.94286420974524|\n",
      "|        EEE|            2014J|79.57708659655404|\n",
      "|        BBB|            2014B|78.60993044822257|\n",
      "|        GGG|            2014B|79.49848392965434|\n",
      "|        DDD|            2013J|69.90850417615793|\n",
      "|        AAA|            2014J|68.75673981191223|\n",
      "|        DDD|            2014J| 71.4885775862069|\n",
      "|        GGG|            2013J|79.93120233652442|\n",
      "|        FFF|            2014J|78.19184161119645|\n",
      "|        AAA|            2013J|69.50537634408602|\n",
      "|        DDD|            2013B|  69.502701760502|\n",
      "|        CCC|            2014J|75.96365316494686|\n",
      "|        BBB|            2013B|78.84378990380523|\n",
      "|        EEE|            2013J|75.08482728465238|\n",
      "|        FFF|            2014B|76.15621524510223|\n",
      "|        DDD|            2014B|69.18938401048493|\n",
      "|        EEE|            2014B|73.98776936517181|\n",
      "|        CCC|            2014B|73.19797030072382|\n",
      "+-----------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join the assessment data with registration to get course and presentation details\n",
    "avg_score_by_course_presentation_df = student_assessment_df.join(student_registration_df, \"id_student\") \\\n",
    "                                                           .groupBy(\"code_module\", \"code_presentation\") \\\n",
    "                                                           .agg(F.avg(\"score\").alias(\"avg_score\"))\n",
    "avg_score_by_course_presentation_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Query: Identify the Most Popular VLE Activity by Course\n",
    "\n",
    "Explanation: We want to determine the most popular VLE activity by course based on the number of views or activities recorded in the vle table.\n",
    "\n",
    "SQL Query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT code_module, activity_type, COUNT(*) AS activity_count\n",
    "FROM vle\n",
    "GROUP BY code_module, activity_type\n",
    "ORDER BY activity_count DESC\n",
    "LIMIT 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------+\n",
      "|code_module|activity_type|activity_count|\n",
      "+-----------+-------------+--------------+\n",
      "|        BBB|     resource|           807|\n",
      "+-----------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a temporary SQL view\n",
    "vle_df.createOrReplaceTempView(\"vle\")\n",
    "\n",
    "# SQL query to group by course and activity type, count activities, and order by activity count\n",
    "query = \"\"\"\n",
    "    SELECT code_module, activity_type, COUNT(*) AS activity_count\n",
    "    FROM vle\n",
    "    GROUP BY code_module, activity_type\n",
    "    ORDER BY activity_count DESC\n",
    "    LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "most_popular_vle_df = spark.sql(query)\n",
    "\n",
    "# Show the results\n",
    "most_popular_vle_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------+\n",
      "|code_module|activity_type|activity_count|\n",
      "+-----------+-------------+--------------+\n",
      "|        BBB|     resource|           807|\n",
      "+-----------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by course and activity type, and count the activities\n",
    "most_popular_vle_df = vle_df.groupBy(\"code_module\", \"activity_type\") \\\n",
    "                            .agg(F.count(\"*\").alias(\"activity_count\")) \\\n",
    "                            .orderBy(F.col(\"activity_count\").desc()) \\\n",
    "                            .limit(1)\n",
    "most_popular_vle_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Query: Students Who Have Failed All Previous Attempts\n",
    "\n",
    "Explanation: We want to find students who have failed every attempt based on the final_result column in the student_info table, where \"Fail\" is the final result.\n",
    "\n",
    "SQL Query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT id_student\n",
    "FROM studentInfo\n",
    "WHERE final_result = 'Fail';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
      "|code_module|code_presentation|id_student|gender|              region|   highest_education|imd_band|age_band|num_of_prev_attempts|studied_credits|disability|final_result|\n",
      "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
      "|        AAA|            2013J|     74372|     M| East Anglian Region|A Level or Equiva...|   10-20|   35-55|                   0|            150|         N|        Fail|\n",
      "|        AAA|            2013J|    146188|     F|West Midlands Region|A Level or Equiva...|  20-30%|    0-35|                   0|             60|         Y|        Fail|\n",
      "|        AAA|            2013J|    147756|     M|        North Region|  Lower Than A Level|  60-70%|    0-35|                   0|            120|         N|        Fail|\n",
      "|        AAA|            2013J|    175991|     F|North Western Region|A Level or Equiva...|  80-90%|    0-35|                   0|            180|         N|        Fail|\n",
      "|        AAA|            2013J|    185439|     M|       London Region|    HE Qualification|   10-20|    0-35|                   0|            120|         N|        Fail|\n",
      "|        AAA|            2013J|    205719|     M| East Anglian Region|A Level or Equiva...|  40-50%|    0-35|                   0|             90|         Y|        Fail|\n",
      "|        AAA|            2013J|    227517|     M|             Ireland|    HE Qualification|    NULL|    0-35|                   0|            180|         N|        Fail|\n",
      "|        AAA|            2013J|    241729|     F|East Midlands Region|    HE Qualification|  60-70%|   35-55|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    268073|     M| East Anglian Region|A Level or Equiva...|   10-20|   35-55|                   0|             90|         N|        Fail|\n",
      "|        AAA|            2013J|    281250|     M|               Wales|  Lower Than A Level|  70-80%|   35-55|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    281589|     M|North Western Region|    HE Qualification|  30-40%|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    295741|     M|   South East Region|A Level or Equiva...|  40-50%|   35-55|                   0|            240|         N|        Fail|\n",
      "|        AAA|            2013J|    302302|     F| East Anglian Region|A Level or Equiva...|  40-50%|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    305152|     M|North Western Region|A Level or Equiva...|  70-80%|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    334259|     F|       London Region|A Level or Equiva...|  50-60%|    0-35|                   0|            150|         N|        Fail|\n",
      "|        AAA|            2013J|    341872|     M| East Anglian Region|  Lower Than A Level|  40-50%|    0-35|                   0|            180|         N|        Fail|\n",
      "|        AAA|            2013J|    344282|     M|    Yorkshire Region|A Level or Equiva...|   10-20|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    346843|     F|            Scotland|    HE Qualification|  50-60%|   35-55|                   0|            120|         N|        Fail|\n",
      "|        AAA|            2013J|    357668|     M|    Yorkshire Region|A Level or Equiva...|   10-20|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    364177|     M| East Anglian Region|  Lower Than A Level|  70-80%|   35-55|                   0|             60|         N|        Fail|\n",
      "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a temporary SQL view\n",
    "student_info_df.createOrReplaceTempView(\"student_info\")\n",
    "\n",
    "# SQL query to filter students who failed\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM student_info\n",
    "    WHERE final_result = 'Fail'\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "failed_students_df = spark.sql(query)\n",
    "\n",
    "# Show the results\n",
    "failed_students_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
      "|code_module|code_presentation|id_student|gender|              region|   highest_education|imd_band|age_band|num_of_prev_attempts|studied_credits|disability|final_result|\n",
      "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
      "|        AAA|            2013J|     74372|     M| East Anglian Region|A Level or Equiva...|   10-20|   35-55|                   0|            150|         N|        Fail|\n",
      "|        AAA|            2013J|    146188|     F|West Midlands Region|A Level or Equiva...|  20-30%|    0-35|                   0|             60|         Y|        Fail|\n",
      "|        AAA|            2013J|    147756|     M|        North Region|  Lower Than A Level|  60-70%|    0-35|                   0|            120|         N|        Fail|\n",
      "|        AAA|            2013J|    175991|     F|North Western Region|A Level or Equiva...|  80-90%|    0-35|                   0|            180|         N|        Fail|\n",
      "|        AAA|            2013J|    185439|     M|       London Region|    HE Qualification|   10-20|    0-35|                   0|            120|         N|        Fail|\n",
      "|        AAA|            2013J|    205719|     M| East Anglian Region|A Level or Equiva...|  40-50%|    0-35|                   0|             90|         Y|        Fail|\n",
      "|        AAA|            2013J|    227517|     M|             Ireland|    HE Qualification|    NULL|    0-35|                   0|            180|         N|        Fail|\n",
      "|        AAA|            2013J|    241729|     F|East Midlands Region|    HE Qualification|  60-70%|   35-55|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    268073|     M| East Anglian Region|A Level or Equiva...|   10-20|   35-55|                   0|             90|         N|        Fail|\n",
      "|        AAA|            2013J|    281250|     M|               Wales|  Lower Than A Level|  70-80%|   35-55|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    281589|     M|North Western Region|    HE Qualification|  30-40%|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    295741|     M|   South East Region|A Level or Equiva...|  40-50%|   35-55|                   0|            240|         N|        Fail|\n",
      "|        AAA|            2013J|    302302|     F| East Anglian Region|A Level or Equiva...|  40-50%|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    305152|     M|North Western Region|A Level or Equiva...|  70-80%|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    334259|     F|       London Region|A Level or Equiva...|  50-60%|    0-35|                   0|            150|         N|        Fail|\n",
      "|        AAA|            2013J|    341872|     M| East Anglian Region|  Lower Than A Level|  40-50%|    0-35|                   0|            180|         N|        Fail|\n",
      "|        AAA|            2013J|    344282|     M|    Yorkshire Region|A Level or Equiva...|   10-20|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    346843|     F|            Scotland|    HE Qualification|  50-60%|   35-55|                   0|            120|         N|        Fail|\n",
      "|        AAA|            2013J|    357668|     M|    Yorkshire Region|A Level or Equiva...|   10-20|    0-35|                   0|             60|         N|        Fail|\n",
      "|        AAA|            2013J|    364177|     M| East Anglian Region|  Lower Than A Level|  70-80%|   35-55|                   0|             60|         N|        Fail|\n",
      "+-----------+-----------------+----------+------+--------------------+--------------------+--------+--------+--------------------+---------------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter the students who failed\n",
    "failed_students_df = student_info_df.filter(student_info_df.final_result == \"Fail\")\n",
    "failed_students_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
